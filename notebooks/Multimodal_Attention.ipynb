{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFZGGQlIMkGK"
      },
      "source": [
        "# Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-M0XcwwMbzO"
      },
      "outputs": [],
      "source": [
        "from datasets import DatasetDict\n",
        "from google.colab import drive\n",
        "import gc\n",
        "import json\n",
        "import librosa\n",
        "from math import ceil\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, cohen_kappa_score, confusion_matrix,classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from transformers import Wav2Vec2Processor, HubertModel\n",
        "from transformers import TrainerCallback\n",
        "from tqdm import tqdm\n",
        "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback, AutoTokenizer, AutoModelForSequenceClassification, AutoModel,get_cosine_schedule_with_warmup\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkWxXtBOMuMp",
        "outputId": "f7e9ae5e-d0da-4631-9608-bd14d3c92168"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_cRt6H1NPB1"
      },
      "source": [
        "# Import Audio Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Rs1PItkNPZE",
        "outputId": "9561ee53-2e2f-4a80-f592-1ce8018d1023"
      },
      "outputs": [],
      "source": [
        "!mkdir -p segments_all\n",
        "!unzip -j -o \"Add satire audio path\" -d segments_all\n",
        "!unzip -j -o \"Add non satire audio path\" -d segments_all"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2qV_OjIPu9N"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ua16PlfnPxJ0"
      },
      "outputs": [],
      "source": [
        "def load_and_prepare_data(split_path: str, audio_dir: str = \"segments_all\"):\n",
        "    \"\"\"\n",
        "    Loads train/validation/test CSV files from the given split path,\n",
        "    maps string labels to integer IDs, and adds a 'path' column with audio file paths.\n",
        "\n",
        "    Args:\n",
        "        split_path (str): Path to the folder containing train.csv, validation.csv, and test.csv.\n",
        "        audio_dir (str): Name of the directory containing the audio files (default: 'segments_all').\n",
        "\n",
        "    Returns:\n",
        "        tuple: (df_train, df_val, df_test, label2id, id2label, labels)\n",
        "    \"\"\"\n",
        "    # CSV file paths\n",
        "    train_file = os.path.join(split_path, \"train.csv\")\n",
        "    val_file = os.path.join(split_path, \"validation.csv\")\n",
        "    test_file = os.path.join(split_path, \"test.csv\")\n",
        "\n",
        "    # Read CSV files\n",
        "    df_train = pd.read_csv(train_file)\n",
        "    df_val = pd.read_csv(val_file)\n",
        "    df_test = pd.read_csv(test_file)\n",
        "\n",
        "    # Create label <-> id mappings\n",
        "    labels = sorted(df_train[\"label\"].unique().tolist())\n",
        "    id2label = {i: label for i, label in enumerate(labels)}\n",
        "    label2id = {label: i for i, label in enumerate(labels)}\n",
        "\n",
        "    print(\"id2label:\", id2label)\n",
        "    print(\"label2id:\", label2id)\n",
        "\n",
        "    # Map labels and build audio file paths\n",
        "    for df in [df_train, df_val, df_test]:\n",
        "        df[\"label\"] = df[\"label\"].map(label2id)\n",
        "        df[\"path\"] = df.apply(\n",
        "            lambda row: f\"{audio_dir}/{row['id']}-{int(row['segment_id'])}.mp3\",\n",
        "            axis=1\n",
        "        )\n",
        "\n",
        "    return df_train, df_val, df_test, label2id, id2label, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfPabqNzNeD9"
      },
      "source": [
        "# Multimodal dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbyz5NT-Wr58"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "def lazy_dataset_generator(df, tokenizer, processor,train=True):\n",
        "    for idx, row in df.iterrows():\n",
        "        text_enc = tokenizer(\n",
        "            row[\"transcription\"], padding=\"max_length\", truncation=True, max_length=76, return_tensors=\"pt\"\n",
        "        )\n",
        "        speech_array, _ = librosa.load(row[\"path\"], sr=16000)\n",
        "        max_samples = 16000 * 10  # 10 seconds at 16 kHz\n",
        "        speech_array = speech_array[:max_samples]\n",
        "        audio_enc = processor(\n",
        "            speech_array, sampling_rate=16000, padding=\"max_length\",\n",
        "            max_length=16000*10, return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        yield {\n",
        "            \"input_ids\": text_enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": text_enc[\"attention_mask\"].squeeze(0),\n",
        "            \"input_values\": audio_enc.input_values.squeeze(0),\n",
        "            \"audio_attention_mask\": audio_enc.attention_mask.squeeze(0),\n",
        "            \"labels\": int(row[\"label\"])\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf9v6bUkQ4yg"
      },
      "source": [
        "# Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvXVy2ufQ661"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = logits.argmax(-1)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "    return {\"accuracy\": acc, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNBoH1ODNutP"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HlvqoywNvxI"
      },
      "outputs": [],
      "source": [
        "class HuBERTEncoder(nn.Module):\n",
        "    def __init__(self, model_name=\"facebook/hubert-base-ls960\"):\n",
        "        super().__init__()\n",
        "        from transformers import AutoModel\n",
        "        self.hubert = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "        for param in self.hubert.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        self.output_dim = self.hubert.config.hidden_size\n",
        "\n",
        "    def forward(self, input_values, attention_mask=None):\n",
        "        outputs = self.hubert(input_values=input_values, attention_mask=attention_mask)\n",
        "        hidden_states = outputs.last_hidden_state  # [B, T_audio, hidden]\n",
        "        return hidden_states  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ls76MXOHN0Vn"
      },
      "outputs": [],
      "source": [
        "class GatedFusion(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.gate = nn.Sequential(\n",
        "            nn.Linear(dim * 2, dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(dim, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, text_vec, audio_vec):\n",
        "        # Concatenate text and audio representations\n",
        "        combined = torch.cat([text_vec, audio_vec], dim=-1)\n",
        "\n",
        "        # Compute the gating coefficient alpha in the range [0, 1]\n",
        "        alpha = self.gate(combined)\n",
        "\n",
        "        # Dynamically fuse the two modalities using the gating mechanism\n",
        "        fused = alpha * text_vec + (1 - alpha) * audio_vec\n",
        "\n",
        "        return fused, alpha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zz-4ikoeN1-d"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    #Sinusoidal positional encoding\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)  # [1, max_len, d_model]\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, T, D]\n",
        "        seq_len = x.size(1)\n",
        "        return x + self.pe[:, :seq_len, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e8ee6zvoN5R1"
      },
      "outputs": [],
      "source": [
        "class MultiModalSatireClassifier(nn.Module):\n",
        "    def __init__(self, text_model_name, fine_tune_layers=6, hidden_dim=256, num_classes=2, num_heads=8):\n",
        "        super().__init__()\n",
        "        # TEXT ENCODER \n",
        "        self.text_encoder = AutoModel.from_pretrained(text_model_name)\n",
        "        text_hidden = self.text_encoder.config.hidden_size\n",
        "\n",
        "        # AUDIO ENCODER \n",
        "        self.audio_encoder = HuBERTEncoder()\n",
        "        audio_hidden = self.audio_encoder.output_dim\n",
        "\n",
        "        # 1D pojection\n",
        "        self.text_proj = nn.Conv1d(text_hidden, hidden_dim, kernel_size=3, padding=1) \n",
        "        self.audio_proj = nn.Conv1d(audio_hidden, hidden_dim, kernel_size=3, padding=1)\n",
        "\n",
        "        # Positional encoding \n",
        "        self.text_pos = PositionalEncoding(hidden_dim)\n",
        "        self.audio_pos = PositionalEncoding(hidden_dim)\n",
        "\n",
        "        # Cross-modal attention \n",
        "        self.cross_attn_text_to_audio = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True)\n",
        "        self.cross_attn_audio_to_text = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True)\n",
        "        self.text_ln = nn.LayerNorm(hidden_dim)\n",
        "        self.audio_ln = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "        # Global inter-modal attention \n",
        "        self.global_attn = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads, batch_first=True)\n",
        "        self.global_ln = nn.LayerNorm(hidden_dim)\n",
        "\n",
        "\n",
        "        # Gated Fusion Layer \n",
        "        self.gate = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "\n",
        "        # Classification Head\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.LayerNorm(hidden_dim),\n",
        "            nn.Dropout(0.4),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.GELU(),\n",
        "            nn.LayerNorm(hidden_dim // 2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim // 2, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "        self.loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, input_values, audio_attention_mask, labels=None):\n",
        "        # TEXT \n",
        "        text_out = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        text_feats = text_out.last_hidden_state                 # [B, T_text, H]\n",
        "        text_feats = text_feats.transpose(1, 2)                # [B, H, T_text]  \n",
        "        text_feats = self.text_proj(text_feats)                # [B, hidden_dim, T_text]\n",
        "        text_feats = text_feats.transpose(1, 2)               # [B, T_text, hidden_dim]\n",
        "        text_feats = self.text_pos(text_feats)                # Positional encoding\n",
        "\n",
        "        # AUDIO \n",
        "        audio_feats = self.audio_encoder(input_values)         # [B, T_audio, H_audio]\n",
        "        audio_feats = audio_feats.transpose(1, 2)             # [B, H_audio, T_audio]\n",
        "        audio_feats = self.audio_proj(audio_feats)            # [B, hidden_dim, T_audio]\n",
        "        audio_feats = audio_feats.transpose(1, 2)            # [B, T_audio, hidden_dim]\n",
        "        audio_feats = self.audio_pos(audio_feats)             # Positional encoding\n",
        "\n",
        "        # Mask\n",
        "        text_kpm = attention_mask == 0                         # True = PAD\n",
        "        if audio_attention_mask is not None:\n",
        "            audio_mask_float = (~audio_attention_mask).float().unsqueeze(1)  # [B,1,T_audio]\n",
        "            audio_mask_down = F.interpolate(audio_mask_float, size=audio_feats.size(1), mode='nearest')\n",
        "            audio_kpm = ~(audio_mask_down.squeeze(1).bool())\n",
        "        else:\n",
        "            audio_kpm = None\n",
        "\n",
        "        # Cross-modal attention \n",
        "        text_attn_out, _ = self.cross_attn_text_to_audio(\n",
        "            query=text_feats, key=audio_feats, value=audio_feats, key_padding_mask=audio_kpm\n",
        "        )\n",
        "        audio_attn_out, _ = self.cross_attn_audio_to_text(\n",
        "            query=audio_feats, key=text_feats, value=text_feats, key_padding_mask=text_kpm\n",
        "        )\n",
        "        text_feats = self.text_ln(text_feats + text_attn_out)\n",
        "        audio_feats = self.audio_ln(audio_feats + audio_attn_out)\n",
        "\n",
        "        # Pooling\n",
        "        text_mask = ~text_kpm if text_kpm is not None else torch.ones(text_feats.size()[:2], dtype=torch.bool, device=text_feats.device)\n",
        "        audio_mask = ~audio_kpm if audio_kpm is not None else torch.ones(audio_feats.size()[:2], dtype=torch.bool, device=audio_feats.device)\n",
        "\n",
        "        text_vec = (text_feats * text_mask.unsqueeze(-1)).sum(dim=1) / text_mask.sum(dim=1, keepdim=True)\n",
        "        audio_vec = (audio_feats * audio_mask.unsqueeze(-1)).sum(dim=1) / audio_mask.sum(dim=1, keepdim=True)\n",
        "\n",
        "        # Dropout \n",
        "        text_vec = F.dropout(text_vec, p=0.2, training=self.training)\n",
        "        audio_vec = F.dropout(audio_vec, p=0.2, training=self.training)\n",
        "\n",
        "        # Global attention \n",
        "        global_input = torch.cat([text_vec.unsqueeze(1), audio_vec.unsqueeze(1)], dim=1)  # [B,2,H]\n",
        "        global_attn_out, _ = self.global_attn(global_input, global_input, global_input)\n",
        "        global_attn_out = self.global_ln(global_attn_out)\n",
        "        global_attn_out = F.dropout(global_attn_out, p=0.2, training=self.training)\n",
        "\n",
        "        text_vec = global_attn_out[:, 0, :]\n",
        "        audio_vec = global_attn_out[:, 1, :]\n",
        "\n",
        "        # Gated fusion\n",
        "        fusion_input = torch.cat([text_vec, audio_vec], dim=-1)\n",
        "        alpha = torch.sigmoid(self.gate(fusion_input))\n",
        "        fused_vec = alpha * text_vec + (1 - alpha) * audio_vec\n",
        "\n",
        "        # Classification\n",
        "        logits = self.classifier(fused_vec)\n",
        "\n",
        "        if labels is not None:\n",
        "            loss = self.loss_fn(logits, labels)\n",
        "            return {\"loss\": loss, \"logits\": logits}\n",
        "        return {\"logits\": logits}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6D2Uao2OKsb"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKzFAoEhXkk8"
      },
      "outputs": [],
      "source": [
        "class EpochLoggerCallback(TrainerCallback):\n",
        "    def __init__(self, steps_per_epoch):\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "        self.current_step = 0\n",
        "\n",
        "    def on_step_end(self, args, state, control, **kwargs):\n",
        "        self.current_step += 1\n",
        "        if self.current_step % self.steps_per_epoch == 0:\n",
        "            print(f\" End epoch {self.current_step // self.steps_per_epoch} \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VD6wLq0SOM7l"
      },
      "outputs": [],
      "source": [
        "def train_hf_model(model, datasets, max_steps, steps_per_epoch, output_dir='./results',\n",
        "                   num_labels=2, train_batch_size=16, eval_batch_size=16,\n",
        "                   num_train_epochs=4, learning_rate=2e-5,\n",
        "                   eval_strategy=\"epoch\", save_strategy=\"epoch\",\n",
        "                   metric_for_best_model=\"eval_f1\", greater_is_better=True,\n",
        "                   compute_metrics=compute_metrics):\n",
        "    \"\"\"\n",
        "    Generic function to train a Hugging Face model using the Trainer API.\n",
        "\n",
        "    Args:\n",
        "        model: Hugging Face model (e.g., AutoModelForSequenceClassification or AutoModelForAudioClassification).\n",
        "        datasets (dict): Dictionary containing 'train' and 'val' Hugging Face Datasets.\n",
        "        max_steps (int): Maximum number of training steps.\n",
        "        steps_per_epoch (int): Number of steps per epoch.\n",
        "        output_dir (str): Output directory for checkpoints and results.\n",
        "        num_labels (int): Number of target classes.\n",
        "        train_batch_size (int): Training batch size per device.\n",
        "        eval_batch_size (int): Evaluation batch size per device.\n",
        "        num_train_epochs (int): Number of training epochs.\n",
        "        learning_rate (float): Learning rate.\n",
        "        eval_strategy (str): Evaluation strategy (\"steps\" or \"epoch\").\n",
        "        save_strategy (str): Checkpoint saving strategy (\"steps\" or \"epoch\").\n",
        "        metric_for_best_model (str): Metric used to select the best model.\n",
        "        greater_is_better (bool): Whether higher metric values indicate better performance.\n",
        "        compute_metrics (callable): Function used to compute evaluation metrics.\n",
        "\n",
        "    Returns:\n",
        "        trainer: Trained Hugging Face Trainer object.\n",
        "        eval_results (dict): Dictionary containing evaluation results.\n",
        "    \"\"\"\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        per_device_train_batch_size=train_batch_size,\n",
        "        per_device_eval_batch_size=eval_batch_size,\n",
        "        num_train_epochs=num_train_epochs,\n",
        "        learning_rate=learning_rate,\n",
        "        eval_strategy=eval_strategy,\n",
        "        save_strategy=save_strategy,\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=metric_for_best_model,\n",
        "        greater_is_better=greater_is_better,\n",
        "        max_steps=max_steps,\n",
        "        fp16=True,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=datasets['train'],\n",
        "        eval_dataset=datasets['val'],\n",
        "        compute_metrics=compute_metrics,\n",
        "        callbacks=[EpochLoggerCallback(steps_per_epoch)]\n",
        "    )\n",
        "\n",
        "    # Start model training\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate the best model on the validation set\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    print(\"Training completed successfully!\")\n",
        "    print(f\"Evaluation results: {eval_results}\")\n",
        "\n",
        "    return trainer, eval_results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zknaU6zwO63p"
      },
      "source": [
        "# Test evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neCLLt3yO8d9"
      },
      "outputs": [],
      "source": [
        "def test_model(model, dataset_test, class_names=None, batch_size=32, average='macro'):\n",
        "    \"\"\"\n",
        "    Runs model inference on the test dataset and computes evaluation metrics.\n",
        "\n",
        "    Args:\n",
        "        model: Trained PyTorch / Hugging Face model.\n",
        "        dataset_test: PyTorch dataset returning model inputs and labels.\n",
        "        class_names (list, optional): List of class names (e.g. ['No Satire', 'Satire']).\n",
        "        batch_size (int): Batch size for inference.\n",
        "        average (str): Averaging strategy for F1, precision and recall\n",
        "                       ('macro', 'weighted', 'micro', etc.).\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing evaluation metrics, predictions and auxiliary information.\n",
        "    \"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    dataloader_test = DataLoader(\n",
        "        dataset_test,\n",
        "        batch_size=batch_size,\n",
        "        drop_last=False,\n",
        "        num_workers=2,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    all_logits = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader_test:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            input_values = batch['input_values'].to(device)\n",
        "            audio_attention_mask = batch['audio_attention_mask'].to(device)\n",
        "            labels = batch['labels']\n",
        "\n",
        "            outputs = model(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                input_values=input_values,\n",
        "                audio_attention_mask=audio_attention_mask\n",
        "            )\n",
        "\n",
        "            # Extract logits from the model output\n",
        "            logits = outputs[\"logits\"]\n",
        "\n",
        "            all_logits.append(logits.cpu())\n",
        "            all_labels.append(labels.cpu())\n",
        "\n",
        "    # Concatenate logits and labels from all batches\n",
        "    all_logits = torch.cat(all_logits, dim=0)\n",
        "    true_labels = torch.cat(all_labels, dim=0).numpy()\n",
        "\n",
        "    # Compute class probabilities and predictions\n",
        "    probabilities = F.softmax(all_logits, dim=1)\n",
        "    predicted_labels = torch.argmax(probabilities, dim=1).numpy()\n",
        "\n",
        "    # Compute evaluation metrics\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    f1 = f1_score(true_labels, predicted_labels, average=average)\n",
        "    precision = precision_score(true_labels, predicted_labels, average=average)\n",
        "    recall = recall_score(true_labels, predicted_labels, average=average)\n",
        "    kappa = cohen_kappa_score(true_labels, predicted_labels)\n",
        "    cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "    if class_names is None:\n",
        "        class_names = [str(i) for i in range(cm.shape[0])]\n",
        "\n",
        "    num_per_class = dict(zip(class_names, np.sum(cm, axis=1)))\n",
        "\n",
        "    # Print evaluation results\n",
        "    print(\"\\nTest Results\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1 Score ({average}): {f1:.4f}\")\n",
        "    print(f\"Precision ({average}): {precision:.4f}\")\n",
        "    print(f\"Recall ({average}): {recall:.4f}\")\n",
        "    print(f\"Cohen Kappa: {kappa:.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(true_labels, predicted_labels, target_names=class_names))\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(\n",
        "        cm,\n",
        "        annot=True,\n",
        "        fmt=\"d\",\n",
        "        cmap=\"Blues\",\n",
        "        xticklabels=class_names,\n",
        "        yticklabels=class_names\n",
        "    )\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"cohen_kappa\": kappa,\n",
        "        \"true_labels\": true_labels,\n",
        "        \"predicted_labels\": predicted_labels,\n",
        "        \"probabilities\": probabilities.numpy(),\n",
        "        \"confusion_matrix\": cm,\n",
        "        \"num_per_class\": num_per_class,\n",
        "        \"class_names\": class_names\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfeSp2UFO_mC"
      },
      "source": [
        "# Save results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dciugYogPBWg"
      },
      "outputs": [],
      "source": [
        "def save_test_results(test_results, save_path):\n",
        "    \n",
        "    \"\"\"\n",
        "    Saves test results to a JSON file and numerical arrays to .npy files.\n",
        "    Automatically handles non-serializable NumPy data types.\n",
        "    \"\"\"\n",
        "\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    array_keys = [\n",
        "        'true_labels',\n",
        "        'predicted_labels',\n",
        "        'probabilities',\n",
        "        'confusion_matrix',\n",
        "        'num_per_class'\n",
        "    ]\n",
        "\n",
        "    def make_serializable(obj):\n",
        "        if isinstance(obj, (np.integer, np.int32, np.int64)):\n",
        "            return int(obj)\n",
        "        elif isinstance(obj, (np.floating, np.float32, np.float64)):\n",
        "            return float(obj)\n",
        "        elif isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        elif isinstance(obj, (set, tuple)):\n",
        "            return list(obj)\n",
        "        else:\n",
        "            return obj\n",
        "\n",
        "    json_results = {k: make_serializable(v) for k, v in test_results.items() if k not in array_keys}\n",
        "\n",
        "    json_file = os.path.join(save_path, 'test_results.json')\n",
        "    with open(json_file, 'w') as f:\n",
        "        json.dump(json_results, f, indent=4)\n",
        "\n",
        "    for key in array_keys:\n",
        "        if key in test_results:\n",
        "            np.save(os.path.join(save_path, f\"{key}.npy\"), test_results[key])\n",
        "\n",
        "    print(f\"Results saved in: {save_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipCMrR55OxI0"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iaO81pQ3Ox8U",
        "outputId": "8c0f49bb-80ca-4971-ad90-22d641b47193"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "from datasets import IterableDataset\n",
        "\n",
        "# Global variables\n",
        "base_path = \"Add cross validation's path\"\n",
        "base_save_path = 'Add saving path'\n",
        "num_splits = 10\n",
        "batch_size = 16\n",
        "model_name = 'dbmdz/bert-base-italian-cased'\n",
        "num_labels = 2\n",
        "num_train_epochs = 4\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
        "\n",
        "for i in range(1, num_splits + 1):\n",
        "    print(f\"\\n Processing Cross {i} \")\n",
        "    split_path = os.path.join(base_path, f'Cross {i}')\n",
        "    df_train, df_val, df_test, label2id, id2label, labels = load_and_prepare_data(split_path)\n",
        "\n",
        "\n",
        "    num_train_examples = len(df_train)\n",
        "    steps_per_epoch = ceil(len(df_train) / batch_size)\n",
        "    max_steps = steps_per_epoch * num_train_epochs\n",
        "    \n",
        "    # Lazi generation of datasets\n",
        "    train_dataset = IterableDataset.from_generator(lambda: lazy_dataset_generator(df_train, tokenizer, processor,train=True))\n",
        "    val_dataset = IterableDataset.from_generator(lambda: lazy_dataset_generator(df_val, tokenizer, processor,train=False))\n",
        "    test_dataset = IterableDataset.from_generator(lambda: lazy_dataset_generator(df_test, tokenizer, processor,train=False))\n",
        "   \n",
        "    # Model\n",
        "    multimodal_model = MultiModalSatireClassifier(\n",
        "        text_model_name=paths['bert_italian'],\n",
        "        hidden_dim=256,\n",
        "        num_classes=num_labels\n",
        "     ).to(device)\n",
        "\n",
        "\n",
        "   # Trainer\n",
        "    trainer, eval_results = train_hf_model(\n",
        "        model=multimodal_model,\n",
        "        datasets={\"train\": train_dataset, \"val\": val_dataset},\n",
        "        train_batch_size=num_train_epochs,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        num_train_epochs = 4,\n",
        "        max_steps=max_steps,\n",
        "        num_labels=num_labels,\n",
        "        output_dir=os.path.join(base_save_path, f'Cross {i}'),\n",
        "    )\n",
        "\n",
        "\n",
        "    # Test\n",
        "    test_results = test_model(\n",
        "        model=multimodal_model,\n",
        "        dataset_test=test_dataset,\n",
        "        class_names=labels,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    save_test_results(test_results, os.path.join(base_save_path, f'Cross {i}'))\n",
        "\n",
        "    # Release unused GPU memory\n",
        "    del multimodal_model, trainer, eval_results, test_results\n",
        "    del train_dataset, val_dataset, test_dataset\n",
        "    torch.cuda.synchronize()\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDrinLpKzwqy"
      },
      "source": [
        "# Cross-validation evaluation with external dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688,
          "referenced_widgets": [
            "36ee551df549404fb91ee235eb859baa",
            "db08a5ef46a34532a628092b81226d08",
            "91f404a42b864e069b7bbe46d3d8217f",
            "147233856801442299c00d9b0d22ce30",
            "f438e652b19a41c5b00409d215cf5e07",
            "0063e04e6a80400b8be5d9176881356f",
            "ae4b4b08121f49db9d5c7f74f12f5b7a",
            "86004be6197d47af8dc9102016299165",
            "ab86a49864964165a00bff3493b96758",
            "8e07b31603af4cd580f1d9aadc6a6e59",
            "0128b347fe6948f2a12dbffb6c5a4a88",
            "3bcff58465ef4d05bed94a76a07a1054",
            "0168b57d0d8c4398931c8ccccd2f0852",
            "5d0c349b372c4b3baa11ac16039aa88a",
            "26ba3308ed9b494a95691a24ed495429",
            "7b4e2c47cc394e8eb94f046b760a22db",
            "f3fde10b531b4648a9ba05058b576b82",
            "21ac9a1563f74052a7e1fbbae49aa213",
            "af72d17f5ad74ac582bd9b90f786978a",
            "15813eb0c4514c4493b1cbbe6886c6ba",
            "445dbd84091142aab0ef4f0159963b4e",
            "29458bdbe4a3444493c379c67dd9a30a",
            "322484806c29467c994112f12839b8f0",
            "4a3d66c20f3a4e83a4b91e50cb97de44",
            "2d8bd3c52af44371a1621d92ed9e076b",
            "0f1d3e55fb8b49968f33606472c12657",
            "0ca4ddd82902445c99c2c5c3668f12e1",
            "77b0521e27fe45929d7c91ee7bba9051",
            "515c019f7ff84ca6ba6296efe8cef3bc",
            "62e7e35a9ff4430e831bbe1d8bc80cb9",
            "2b247bbc27bb457d81066c1c38aef0f4",
            "eafba4d0e03048db875aff6dc3887add",
            "11fdec7a85134b9bbc0140602fe11a35"
          ]
        },
        "id": "1araJ5VLz1c8",
        "outputId": "9c32fae1-b0ed-44a9-d7c8-ef46b20072ae"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset, DatasetDict\n",
        "from datasets import IterableDataset\n",
        "\n",
        "# Global variables\n",
        "base_path = \"Add cross validation's path\"\n",
        "base_save_path = 'Add saving path'\n",
        "\n",
        "num_splits = 10\n",
        "batch_size = 16\n",
        "model_name = 'dbmdz/bert-base-italian-cased'\n",
        "num_labels = 2\n",
        "num_train_epochs = 4\n",
        "i=1\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
        "\n",
        "print(f\"\\n Processing \")\n",
        "\n",
        "# Dataset\n",
        "split_path = os.path.join(base_path, f'Cross {i}')\n",
        "df_train, df_val, df_test, label2id, id2label, labels = load_and_prepare_data(split_path)\n",
        "df_all= pd.concat([df_train, df_val, df_test])\n",
        "df_all = df_all.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "df_train, df_val = train_test_split(df_all, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "num_train_examples = len(df_train)\n",
        "steps_per_epoch = ceil(len(df_train) / batch_size)\n",
        "max_steps = steps_per_epoch * num_train_epochs\n",
        "\n",
        "train_dataset = IterableDataset.from_generator(lambda: lazy_dataset_generator(df_train, tokenizer, processor,train=True))\n",
        "val_dataset = IterableDataset.from_generator(lambda: lazy_dataset_generator(df_val, tokenizer, processor,train=False))\n",
        "\n",
        "\n",
        "multimodal_model = MultiModalSatireClassifier(\n",
        "        text_model_name=paths['bert_italian'],\n",
        "        hidden_dim=256,\n",
        "        num_classes=num_labels\n",
        "     ).to(device)\n",
        "\n",
        "\n",
        "# Trainer\n",
        "trainer, eval_results = train_hf_model(\n",
        "        model=multimodal_model,\n",
        "        datasets={\"train\": train_dataset, \"val\": val_dataset},\n",
        "        train_batch_size=num_train_epochs,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        num_train_epochs = 4,\n",
        "        max_steps=max_steps,\n",
        "        num_labels=num_labels,\n",
        "        output_dir=os.path.join(base_save_path, f'Cross {i}'),\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        },
        "id": "-_nS20cW0X4P",
        "outputId": "2a86e6e3-efcb-4bc9-92cf-cf3a144128b2"
      },
      "outputs": [],
      "source": [
        "dataset_esterno_path = \"Add external dataset's path\"  # Path to external dataset\n",
        "base_save_path = \"Add external dataset's result path\"  # Path to save results\n",
        "\n",
        "audio_dir: str = \"segments_all\"\n",
        "\n",
        "# CSV file\n",
        "external_file= os.path.join( dataset_esterno_path, 'dataset_2k.csv')\n",
        "\n",
        "df_external = pd.read_csv(external_file)\n",
        "\n",
        "# Create label <-> ID mapping\n",
        "df_external['label'] = df_external['label'].map(label2id)\n",
        "df_external[\"path\"] = df_external.apply(\n",
        "            lambda row: f\"{audio_dir}/{row['id']}-{int(row['segment_id'])}.mp3\", axis=1\n",
        "        )\n",
        "\n",
        "external_dataset = IterableDataset.from_generator(lambda: lazy_dataset_generator(df_external, tokenizer, processor,train=False))\n",
        "\n",
        "# Test\n",
        "print(f\"\\n Test datasert external\")\n",
        "test_results = test_model(\n",
        "        model=multimodal_model,\n",
        "        dataset_test=external_dataset,\n",
        "        class_names=labels,\n",
        "        batch_size=32\n",
        "    )\n",
        "\n",
        "# Save results\n",
        "save_path = os.path.join(base_save_path, f'Cross {i}')\n",
        "save_test_results(test_results, save_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0063e04e6a80400b8be5d9176881356f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0128b347fe6948f2a12dbffb6c5a4a88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0168b57d0d8c4398931c8ccccd2f0852": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3fde10b531b4648a9ba05058b576b82",
            "placeholder": "​",
            "style": "IPY_MODEL_21ac9a1563f74052a7e1fbbae49aa213",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "0ca4ddd82902445c99c2c5c3668f12e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f1d3e55fb8b49968f33606472c12657": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eafba4d0e03048db875aff6dc3887add",
            "placeholder": "​",
            "style": "IPY_MODEL_11fdec7a85134b9bbc0140602fe11a35",
            "value": " 378M/378M [00:02&lt;00:00, 259MB/s]"
          }
        },
        "11fdec7a85134b9bbc0140602fe11a35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "147233856801442299c00d9b0d22ce30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e07b31603af4cd580f1d9aadc6a6e59",
            "placeholder": "​",
            "style": "IPY_MODEL_0128b347fe6948f2a12dbffb6c5a4a88",
            "value": " 1.39k/? [00:00&lt;00:00, 97.8kB/s]"
          }
        },
        "15813eb0c4514c4493b1cbbe6886c6ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21ac9a1563f74052a7e1fbbae49aa213": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26ba3308ed9b494a95691a24ed495429": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_445dbd84091142aab0ef4f0159963b4e",
            "placeholder": "​",
            "style": "IPY_MODEL_29458bdbe4a3444493c379c67dd9a30a",
            "value": " 378M/378M [00:03&lt;00:00, 195MB/s]"
          }
        },
        "29458bdbe4a3444493c379c67dd9a30a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b247bbc27bb457d81066c1c38aef0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d8bd3c52af44371a1621d92ed9e076b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62e7e35a9ff4430e831bbe1d8bc80cb9",
            "max": 377510580,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b247bbc27bb457d81066c1c38aef0f4",
            "value": 377510580
          }
        },
        "322484806c29467c994112f12839b8f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a3d66c20f3a4e83a4b91e50cb97de44",
              "IPY_MODEL_2d8bd3c52af44371a1621d92ed9e076b",
              "IPY_MODEL_0f1d3e55fb8b49968f33606472c12657"
            ],
            "layout": "IPY_MODEL_0ca4ddd82902445c99c2c5c3668f12e1"
          }
        },
        "36ee551df549404fb91ee235eb859baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_db08a5ef46a34532a628092b81226d08",
              "IPY_MODEL_91f404a42b864e069b7bbe46d3d8217f",
              "IPY_MODEL_147233856801442299c00d9b0d22ce30"
            ],
            "layout": "IPY_MODEL_f438e652b19a41c5b00409d215cf5e07"
          }
        },
        "3bcff58465ef4d05bed94a76a07a1054": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0168b57d0d8c4398931c8ccccd2f0852",
              "IPY_MODEL_5d0c349b372c4b3baa11ac16039aa88a",
              "IPY_MODEL_26ba3308ed9b494a95691a24ed495429"
            ],
            "layout": "IPY_MODEL_7b4e2c47cc394e8eb94f046b760a22db"
          }
        },
        "445dbd84091142aab0ef4f0159963b4e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a3d66c20f3a4e83a4b91e50cb97de44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77b0521e27fe45929d7c91ee7bba9051",
            "placeholder": "​",
            "style": "IPY_MODEL_515c019f7ff84ca6ba6296efe8cef3bc",
            "value": "model.safetensors: 100%"
          }
        },
        "515c019f7ff84ca6ba6296efe8cef3bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d0c349b372c4b3baa11ac16039aa88a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af72d17f5ad74ac582bd9b90f786978a",
            "max": 377569754,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15813eb0c4514c4493b1cbbe6886c6ba",
            "value": 377569754
          }
        },
        "62e7e35a9ff4430e831bbe1d8bc80cb9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77b0521e27fe45929d7c91ee7bba9051": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b4e2c47cc394e8eb94f046b760a22db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86004be6197d47af8dc9102016299165": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "8e07b31603af4cd580f1d9aadc6a6e59": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91f404a42b864e069b7bbe46d3d8217f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86004be6197d47af8dc9102016299165",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab86a49864964165a00bff3493b96758",
            "value": 1
          }
        },
        "ab86a49864964165a00bff3493b96758": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae4b4b08121f49db9d5c7f74f12f5b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af72d17f5ad74ac582bd9b90f786978a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db08a5ef46a34532a628092b81226d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0063e04e6a80400b8be5d9176881356f",
            "placeholder": "​",
            "style": "IPY_MODEL_ae4b4b08121f49db9d5c7f74f12f5b7a",
            "value": "config.json: "
          }
        },
        "eafba4d0e03048db875aff6dc3887add": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3fde10b531b4648a9ba05058b576b82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f438e652b19a41c5b00409d215cf5e07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
